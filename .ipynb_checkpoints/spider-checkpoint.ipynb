{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "res=requests.get('http://news.sina.com.cn/c/nd/2018-06-08/doc-ihcscwxa1809510.shtml')\n",
    "res.encoding='utf-8'\n",
    "soup=BeautifulSoup(res.text,'html.parser')    \n",
    "title=soup.select('.main-title')[0].text\n",
    "#timesource1=soup.select('.date-source')[0].text.split('\\n')[1]    #获取时间\n",
    "timesource=soup.select('.date-source span')[0].text         #获取时间\n",
    "dt=datetime.strptime(timesource,'%Y年%m月%d日 %H:%M')\n",
    "dt.strftime('%Y-%m-%d')\n",
    "place=soup.select('.date-source a')[0].text    #获取新闻来源\n",
    "article=[]                                   #获取文章内容\n",
    "for p in soup.select('#article p')[:-1]:\n",
    "    article.append(p.text.strip())\n",
    "articleall=' '.join(article)\n",
    "editor=soup.select('#article p')[-1].text.strip('责任编辑：')     #获取作者姓名\n",
    "comments=requests.get('http://comment5.news.sina.com.cn/page/info?version=1&format=json&\\\n",
    "channel=gn&newsid=comos-hcscwxa1809510&group=undefined&compress=0&ie=utf-8&\\\n",
    "oe=utf-8&page=1&page_size=3&t_size=3&h_size=3&thread=1')                      \n",
    "#print(comments.text)    \n",
    "jd=json.loads(comments.text)         #用jason解析器\n",
    "comment_num=jd['result']['count']['total']        #获得评论总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#newsurl='http://news.sina.com.cn/c/nd/2018-06-08/doc-ihcscwxa1809510.shtml'\n",
    "\n",
    "newsurl = 'https://news.sina.com.cn/c/zj/2019-06-12/doc-ihvhiqay5255597.shtml'\n",
    "commenturl='http://comment5.news.sina.com.cn/page/info?version=1&format=json&channel=gn&newsid=comos-{}&group=undefined&compress=0&ie=utf-8&oe=utf-8&page=1&page_size=3&t_size=3&h_size=3&thread=1'\n",
    "def getcommentcounts(newsurl):            #获取评论数\n",
    "    m=re.compile('doc-i(.*?).shtml').findall(newsurl)\n",
    "    newsid=m[0]\n",
    "    comments=requests.get(commenturl.format(newsid))\n",
    "    jd=json.loads(comments.text)\n",
    "    return jd['result']['count']['total']\n",
    " \n",
    "def getnewsdetail(newsurl):                                        #获得单页的新闻内容\n",
    "    result={}\n",
    "    res=requests.get(newsurl)\n",
    "    res.encoding='utf-8'\n",
    "    soup=BeautifulSoup(res.text,'html.parser')\n",
    "    result['title']=soup.select('.main-title')[0].text      #标题\n",
    "    timesource=soup.select('.date-source span')[0].text  \n",
    "    result['time']=datetime.strptime(timesource,'%Y年%m月%d日 %H:%M').strftime('%Y-%m-%d')              #时间\n",
    "    result['place']=soup.select('.source')[0].text       #来源\n",
    "    article=[]                                   #获取文章内容\n",
    "    for p in soup.select('#article p')[:-1]:\n",
    "        article.append(p.text.strip())\n",
    "    articleall=' '.join(article)\n",
    "    result['article']=articleall\n",
    "    result['editor']=soup.select('#article p')[-1].text.strip('责任编辑：')     #获取作者姓名\n",
    "    result['comment_num']=getcommentcounts(newsurl)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getnewsdetail(newsurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_url = 'https://news.sina.com.cn/c/zj/2019-06-12/doc-ihvhiqay5255597.shtml'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url='http://api.roll.news.sina.com.cn/zt_list?channel=news&cat_1=gnxw&cat_2==gdxw1||=gatxw||=zs-pl||=mtjj&level==1||=2&show_ext=1&show_all=1&show_num=22&tag=1&format=json&page={}&callback=newsloadercallback&_=1528548757769'\n",
    "def parseListLinks(url):\n",
    "    newsdetail=[]\n",
    "    res=requests.get(url)\n",
    "    print(res.text)\n",
    "    jd=json.loads(res.text.lstrip('  newsloadercallback(').rstrip(');'))\n",
    "    for ent in jd['result']['data']:\n",
    "        newsdetail.append(getnewsdetail(ent['url']))\n",
    "    return newsdetail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_total=[]\n",
    "for i in range(1,2):\n",
    "    newsurl=url.format(i)\n",
    "    newsary=parseListLinks(newsurl)\n",
    "    news_total.extend(newsary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(news_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "def download(title, url,m):\n",
    "    req = request.Request(url)\n",
    "    response = request.urlopen(req)\n",
    "    response = response.read().decode('utf-8')\n",
    "    soup = BeautifulSoup(response,'lxml')\n",
    "    tag = soup.find('div',class_='article')\n",
    "    if tag == None:\n",
    "        return 0\n",
    "    #print(type(tag))\n",
    "    #print(tag.get_text())\n",
    "    title = title.replace(':','')\n",
    "    title = title.replace('\"','')\n",
    "    title = title.replace('|','')\n",
    "    title = title.replace('/','')\n",
    "    title = title.replace('\\\\','')\n",
    "    title = title.replace('*','')\n",
    "    title = title.replace('<','')\n",
    "    title = title.replace('>','')\n",
    "    title = title.replace('?','')\n",
    "    #print(tag.get_text())\n",
    "    filename = r'D:\\code\\python\\spider_news\\sina_news\\sociaty\\\\' +title+'.txt'\n",
    "    with open(filename,'w',encoding='utf8') as file_object:\n",
    "        file_object.write('           ')\n",
    "        file_object.write(title)\n",
    "        file_object.write(tag.get_text())\n",
    "    print('正在爬取第', m,'个新闻',title)\n",
    "    return 0\n",
    "if __name__ == '__main__':\n",
    "    target_url = 'http://news.sina.com.cn/society/'\n",
    "    req = request.Request(target_url)\n",
    "    response = request.urlopen(req)\n",
    "    response = response.read().decode('utf8')\n",
    "    #print(response)\n",
    "    soup = BeautifulSoup(response,'lxml')\n",
    "    #print(soup.prettify())\n",
    "    #file = open('d:\\\\test2.txt','w',encoding='utf8')\n",
    "    #file.write(soup.prettify())\n",
    "    y = 0\n",
    "    for tag in soup.find_all('div',class_='news-item'):\n",
    "        if tag.a != None:\n",
    "            if len(tag.a.string) > 8:\n",
    "                 #print(tag.a.string,tag.a.get('href'))\n",
    "                 temp = tag.a.string\n",
    "                 y += 1\n",
    "                 download(temp,tag.a.get('href'),y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1-1-36504939', 'column': '', 'title': '推进人工智能发展需各方联合行动', 'url': 'http://news.sina.com.cn/c/2018-11-20/doc-ihnyuqhi5168899.shtml', 'keywords': '人工智能,联合行动,肖立志', 'comment_channel': 'gn', 'img': '', 'level': '0', 'createtime': '1542722573', 'old_level': '3', 'media_type': '', 'media_name': '中国经济网'}\n",
      "正在写入csv文件中\n",
      "{'id': '1-1-36504938', 'column': '', 'title': '人民日报评论员：为世界经济拓展新的增长空间', 'url': 'http://news.sina.com.cn/o/2018-11-20/doc-ihmutuec2061859.shtml', 'keywords': '一带一路,世界经济,评论员', 'comment_channel': '', 'img': '', 'level': '0', 'createtime': '1542722528', 'old_level': '3', 'media_type': '', 'media_name': '人民日报'}\n",
      "正在写入csv文件中\n",
      "{'id': '1-1-36504936', 'column': '', 'title': '“银狐”国内告别战，球迷横幅上写着“里皮先生谢谢您”', 'url': 'http://news.sina.com.cn/c/2018-11-20/doc-ihmutuec2061390.shtml', 'keywords': '体育场,里皮,银狐', 'comment_channel': 'gn', 'img': '', 'level': '0', 'createtime': '1542722425', 'old_level': '3', 'media_type': '', 'media_name': '新京报'}\n",
      "正在写入csv文件中\n",
      "{'id': '1-1-36504932', 'column': '', 'title': '台中市长选举进入倒计时 9成新住民愿投“蓝营”', 'url': 'http://news.sina.com.cn/c/2018-11-20/doc-ihnyuqhi5163611.shtml', 'keywords': '台中,蓝营,选举', 'comment_channel': 'gn', 'img': '', 'level': '1', 'createtime': '1542722287', 'old_level': '1', 'media_type': '', 'media_name': '海外网'}\n",
      "正在写入csv文件中\n",
      "{'id': '1-1-36504926', 'column': '', 'title': '支持配合在上交所设立科创板并试点注册制，李强今调研并就这个资本市场基地建设提要求', 'url': 'http://news.sina.com.cn/c/2018-11-20/doc-ihmutuec2060553.shtml', 'keywords': '交通银行,李强,科创', 'comment_channel': 'gn', 'img': '', 'level': '0', 'createtime': '1542722095', 'old_level': '3', 'media_type': '', 'media_name': '上观'}\n",
      "正在写入csv文件中\n",
      "{'id': '1-1-36504882', 'column': '', 'title': '习近平出席菲律宾总统举行的欢迎仪式', 'url': 'http://news.sina.com.cn/w/2018-11-20/doc-ihnyuqhi5135084.shtml', 'keywords': '', 'comment_channel': 'gj', 'img': '', 'level': '0', 'createtime': '1542720933', 'old_level': '3', 'media_type': '', 'media_name': '央视'}\n",
      "正在写入csv文件中\n",
      "{'id': '1-1-36504842', 'column': '', 'title': '俄罗斯代表团访朝 向金正恩赠送神秘礼物(图)', 'url': 'http://news.sina.com.cn/w/2018-11-20/doc-ihnyuqhi5111172.shtml', 'keywords': '金正恩,朝鲜,俄罗斯', 'comment_channel': 'gj', 'img': '', 'level': '1', 'createtime': '1542719844', 'old_level': '1', 'media_type': '', 'media_name': '海外网'}\n",
      "正在写入csv文件中\n",
      "{'id': '1-1-36504815', 'column': '', 'title': '印度一座军火库发生爆炸 已经导致至少6人死亡', 'url': 'http://news.sina.com.cn/w/2018-11-20/doc-ihmutuec2049684.shtml', 'keywords': '军火库,印度,死亡', 'comment_channel': 'gj', 'img': '', 'level': '0', 'createtime': '1542719125', 'old_level': '3', 'media_type': '', 'media_name': '中国新闻网'}\n",
      "正在写入csv文件中\n",
      "{'id': '1-1-36504843', 'column': '', 'title': '印度一军火库发生爆炸 已造成6人死亡18人受伤', 'url': 'http://news.sina.com.cn/w/2018-11-20/doc-ihmutuec2049655.shtml', 'keywords': '军火库,受伤,印度', 'comment_channel': 'gj', 'img': '', 'level': '1', 'createtime': '1542719119', 'old_level': '1', 'media_type': '', 'media_name': '海外网'}\n",
      "正在写入csv文件中\n",
      "{'id': '1-1-36504849', 'column': '', 'title': '印度豪投5亿美元 请俄罗斯帮忙再造两艘护卫舰', 'url': 'http://news.sina.com.cn/w/2018-11-20/doc-ihmutuec2049631.shtml', 'keywords': '护卫舰,印度,俄罗斯', 'comment_channel': 'gj', 'img': '', 'level': '0', 'createtime': '1542719113', 'old_level': '2', 'media_type': '', 'media_name': '环球网'}\n",
      "正在写入csv文件中\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import threading\n",
    "import multiprocessing\n",
    "import json\n",
    "from urllib.parse import urlencode\n",
    "from urllib.request import urlopen,Request,urlparse,build_opener,install_opener\n",
    "from urllib.error import URLError,HTTPError\n",
    "\n",
    "def html_download(url):\n",
    "\n",
    "    headers = {'User-Agent': \"User-Agent:Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)\"}\n",
    "    request = Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urlopen(request).read().decode()\n",
    "    except HTTPError as e:\n",
    "        html = None\n",
    "        print('[W] 下载出现服务器错误: %s' % e.reason)\n",
    "        return None\n",
    "    except URLError as e:\n",
    "        html = None\n",
    "        print(\"[E] 站点不可达: %s\" % e.reason)\n",
    "        return None\n",
    "    return html\n",
    "\n",
    " \n",
    "def api_info_manager(page):\n",
    "    #http://api.roll.news.sina.com.cn/zt_list?channel=news&cat_1=gnxw&show_all=1&show_num=6000&tag=1&format=json\n",
    "    comment_channel = [ 'gnxw', 'shxw','gjxw']\n",
    "    for comment in comment_channel: \n",
    "\n",
    "        data= {\n",
    "            'channel':'news',\n",
    "            'cat_1':comment,\n",
    "            'show_all':1,\n",
    "            'show_num':5,\n",
    "            'tag':1,\n",
    "            'page':page,\n",
    "            'format':'json'\n",
    "            }\n",
    "        dataformat = 'http://api.roll.news.sina.com.cn/zt_list?'+urlencode(data)\n",
    "        response = html_download(dataformat)\n",
    "        #print(response)\n",
    "        json_results = json.loads(response,encoding='utf-8')['result']['data']\n",
    "        \n",
    "        for info_dict in json_results:\n",
    "            print(info_dict)\n",
    "            yield info_dict\n",
    " \n",
    " \n",
    "fileheader = ['id','column','title','url','keywords','comment_channel','img','level','createtime','old_level','media_type','media_name']\n",
    "\n",
    "\n",
    "def write_csv_header(fileheader):\n",
    "    with open(\"新浪新闻.csv\", \"a\",newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fileheader)\n",
    "        writer.writeheader()\n",
    "\n",
    "    \n",
    "def save_to_csv(result):\n",
    "    with open(\"新浪新闻.csv\", \"a\",newline='') as csvfile:\n",
    "        print('正在写入csv文件中')\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fileheader)\n",
    "        writer.writerow(result)\n",
    "\n",
    "\n",
    "def main(page):\n",
    "    for res in api_info_manager(page):\n",
    "        save_to_csv(res)\n",
    "\n",
    "write_csv_header(fileheader)\n",
    "main(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #多线程  \n",
    "    write_csv_header(fileheader)   \n",
    "    pool = multiprocessing.Pool()  \n",
    "    # 多进程  \n",
    "    thread = threading.Thread(target=pool.map,args = (main,[x for x in range(1, 100)]))  \n",
    "    thread.start()  \n",
    "    thread.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
